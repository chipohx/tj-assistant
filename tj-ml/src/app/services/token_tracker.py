"""Token usage tracking for LLM API calls."""
from typing import Any, Dict, List
from langchain_core.callbacks import BaseCallbackHandler
from langchain_core.outputs import LLMResult
from app.core.logging import get_logger


logger = get_logger(__name__)


class TokenUsageCallback(BaseCallbackHandler):
    """
    Callback handler –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ —Å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–µ–π.
    
    –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç:
    - –¢–æ–∫–µ–Ω—ã –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    - –¢–æ–∫–µ–Ω—ã –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ RAG (–≤–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î)
    - –¢–æ–∫–µ–Ω—ã –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏
    """
    
    def __init__(self, query_tokens: int = 0, context_tokens: int = 0):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è callback.
        
        Args:
            query_tokens: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∑–∞–ø—Ä–æ—Å–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            context_tokens: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –∏–∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î
        """
        self.total_tokens = 0
        self.prompt_tokens = 0
        self.completion_tokens = 0
        self.successful_requests = 0
        self.query_tokens = query_tokens
        self.context_tokens = context_tokens
        
    def on_llm_start(
        self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any
    ) -> None:
        """–í—ã–∑—ã–≤–∞–µ—Ç—Å—è –≤ –Ω–∞—á–∞–ª–µ LLM –∑–∞–ø—Ä–æ—Å–∞."""
        pass
    
    def on_llm_end(self, response: LLMResult, **kwargs: Any) -> None:
        """–í—ã–∑—ã–≤–∞–µ—Ç—Å—è –≤ –∫–æ–Ω—Ü–µ LLM –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø–æ–¥—Å—á—ë—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤."""
        if response.llm_output is None:
            return
            
        token_usage = response.llm_output.get("token_usage", {})
        
        if token_usage:
            prompt_tokens = token_usage.get("prompt_tokens", 0)
            completion_tokens = token_usage.get("completion_tokens", 0)
            total_tokens = token_usage.get("total_tokens", 0)
            
            # –ï—Å–ª–∏ total_tokens –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω, –≤—ã—á–∏—Å–ª—è–µ–º
            if not total_tokens and (prompt_tokens or completion_tokens):
                total_tokens = prompt_tokens + completion_tokens
            
            self.prompt_tokens += prompt_tokens
            self.completion_tokens += completion_tokens
            self.total_tokens += total_tokens
            self.successful_requests += 1
            
            logger.info(
                f"üìä Token Usage - "
                f"Query: {self.query_tokens}, "
                f"Context: {self.context_tokens}, "
                f"Total Input: {prompt_tokens}, "
                f"Output: {completion_tokens}, "
                f"Total: {total_tokens}"
            )
    
    def on_llm_error(self, error: Exception, **kwargs: Any) -> None:
        """–í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –æ—à–∏–±–∫–µ LLM."""
        logger.error(f"‚ùå LLM Error: {error}")
    
    def get_usage_stats(self) -> Dict[str, int]:
        """–ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤."""
        return {
            "total_tokens": self.total_tokens,
            "prompt_tokens": self.prompt_tokens,
            "completion_tokens": self.completion_tokens,
            "successful_requests": self.successful_requests,
            "query_tokens": self.query_tokens,
            "context_tokens": self.context_tokens,
        }
    
    def reset(self) -> None:
        """–°–±—Ä–æ—Å–∏—Ç—å —Å—á—ë—Ç—á–∏–∫–∏."""
        self.total_tokens = 0
        self.prompt_tokens = 0
        self.completion_tokens = 0
        self.successful_requests = 0
