#--extra-index-url https://download.pytorch.org/whl/cpu
--extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu124/
torch==2.7.1
python-dotenv~=1.1.1
llama-cpp-python==0.3.9
fastapi==0.115.13
uvicorn==0.34.3
huggingface-hub==0.35.3